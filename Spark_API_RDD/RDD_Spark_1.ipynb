{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5YQYY6z2At_O"
      },
      "outputs": [],
      "source": [
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "        .appName(\"RDD Intro\")\\\n",
        "        .master(\"local[*]\")\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "lHBJMEkvA-wq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "         \"Goku Vegeta Gohan\",\n",
        "         \"Goku Frieza Goku\",\n",
        "         \"Vegeta Goku Frieza Gohan\",\n",
        "         \"Gohan Frieza Goku Goku\"\n",
        "        ]"
      ],
      "metadata": {
        "id": "ekYKazwoBEi_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`we use parallelize() function wehne working someting in memory like Array , List , Numpy `"
      ],
      "metadata": {
        "id": "VfNs5Kg3-3Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize(data)\n",
        "rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0PFCVThB21t",
        "outputId": "896239dd-b8d8-4c5a-ae07-b89a4b7f9256"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Goku Vegeta Gohan',\n",
              " 'Goku Frieza Goku',\n",
              " 'Vegeta Goku Frieza Gohan',\n",
              " 'Gohan Frieza Goku Goku']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = rdd.flatMap(lambda line: line.split(\" \"))\n",
        "rdd2 = rdd1.map(lambda word: (word, 1))\n",
        "rdd3 = rdd2.reduceByKey(lambda x, y: x + y)"
      ],
      "metadata": {
        "id": "0J_yIxBGBoXP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdd3.toDebugString())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6XUbO5JDOE6",
        "outputId": "c27b81fe-01e8-4915-afbc-d58ea567578a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'(2) PythonRDD[14] at RDD at PythonRDD.scala:53 []\\n |  MapPartitionsRDD[13] at mapPartitions at PythonRDD.scala:160 []\\n |  ShuffledRDD[12] at partitionBy at NativeMethodAccessorImpl.java:0 []\\n +-(2) PairwiseRDD[11] at reduceByKey at /tmp/ipython-input-1185989728.py:3 []\\n    |  PythonRDD[10] at reduceByKey at /tmp/ipython-input-1185989728.py:3 []\\n    |  ParallelCollectionRDD[9] at readRDDFromFile at PythonRDD.scala:289 []'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Number of parttition of this data that we create in memory park partition this data just in memory we have in tis case just 2 partitions`"
      ],
      "metadata": {
        "id": "09T--aMJ2KHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4o5dUi61Ts4",
        "outputId": "5b1c85b1-b615-45c6-d5fb-9f554ab4cc51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`in local machine , mean we using one machine number parallisme is equals of number of partition`"
      ],
      "metadata": {
        "id": "cepyVtrA-pu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.defaultParallelism"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4DpEIOW9XFa",
        "outputId": "8c4b0f8a-078a-426b-c7ae-c1efb4db3eb3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`max of bytes that can have blocks or partition , mean how much max bytes in each partitions`"
      ],
      "metadata": {
        "id": "-fijQv3N2b0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"max Partition Bytes: {spark.conf.get('spark.sql.files.maxPartitionBytes')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF5CHA601fmD",
        "outputId": "4c881b6a-ff31-4233-b25b-f7ad6792821a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max Partition Bytes: 134217728b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`default partition that spark divide data`"
      ],
      "metadata": {
        "id": "LAqQS9AJ2vbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.defaultMinPartitions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKDRH5Sf2r38",
        "outputId": "f4c123c6-588c-4c87-d8e8-e6b0ed84445d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}